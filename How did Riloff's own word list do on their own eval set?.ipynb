{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import operator\n",
    "import os\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "orig_paper_predicate_expr = set([\"great\", \"so much fun\", \"good\", \"so happy\", \"better\", \"my favorite thing\", \"cool\", \"funny\", \"nice\", \"always fun\", \"fun\", \"awesome\", \"the best feeling\", \"amazing\", \"happy\", \"ready today\", \"ready\", \"dry\", \"juicy\", \"my favorite part\"])\n",
    "orig_paper_pos_expr = set([\"love\", \"missed\", \"loves\", \"enjoy\", \"cant wait\", \"excited\", \"wanted\", \"can't wait\", \"get\", \"appreciate\", \"decided\", \"loving\", \"really like\", \"looooove\", \"just keeps\", \"loveee\", \"randomly stop\", \"cannot wait\", \"just live\", \"please keep\", \"live\", \"stoked\", \"goin\", \"reading\", \"break\", \"just stops\", \"stops\"])\n",
    "orig_paper_neg_expr = set([\"being ignored\", \"being sick\", \"waiting\", \"feeling\", \"waking up early\", \"being woken\", \"fighting\", \"staying\", \"writing\", \"being home\", \"cleaning\", \"not getting\", \"crying\", \"sitting at home\", \"being stuck\", \"starting\", \"being told\", \"being left\", \"getting ignored\", \"being treated\", \"doing homework\", \"learning\", \"getting up early\", \"going to bed\", \"getting sick\", \"riding\", \"being ditched\", \"getting ditched\", \"missing\", \"not sleeping\", \"not talking\", \"trying\", \"falling\", \"walking home\", \"getting yelled\", \"being awake\", \"being talked\", \"taking care\", \"doing nothing\", \"wasting\", \"throwing\", \"getting woken up\", \"to spend\", \"standing\", \"smelling\", \"getting woken\", \"arguing\", \"paying bills\", \"being locked\", \"shoveling\", \"getting called\", \"being at work\", \"having nothing\", \"getting invited\", \"getting blown\", \"dealing\", \"ending\", \"to wake\", \"when doesn't text\", \"getting ready\", \"to learn\", \"picking\", \"walking to class\", \"breaking\", \"being invited\", \"getting home\", \"setting\", \"dropping\", \"not seeing\", \"forgetting\", \"being called fat\", \"getting lied\", \"invited\", \"to sit here\", \"to be ignored\", \"being late\", \"doing laundry\", \"being taken\", \"practicing\", \"babysitting\", \"getting hit\", \"being used\", \"being used\", \"being reminded\", \"when falls\", \"working all day\", \"running late\", \"traveling\", \"peeing\", \"being hit\", \"having practice\", \"not being invited\", \"being bored\", \"stepping\", \"spending my day\", \"leaving\", \"almost getting\", \"being put\", \"passing\", \"being at school\", \"to study\", \"going to class\", \"coughing\", \"sitting in traffic\", \"being yelled\", \"fixing\", \"burning\", \"walking to school\", \"wakin\", \"seeing people\", \"being accused\", \"being up early\", \"scratches\", \"texting someone\", \"being invited places\", \"receiving\", \"being grounded\", \"checking\", \"getting my ass\", \"getting back\", \"getting bitched\", \"getting treated\", \"only getting\", \"reviewing\", \"sitting alone\", \"getting screwed\", \"going there\", \"getting stared\", \"calling\", \"watching scary movies\", \"getting no sleep\", \"taking tests\", \"getting locked\", \"reading tweets\", \"teaching\", \"waking up not\", \"sounding\", \"getting made\", \"sleeping alone\", \"not feeling\", \"being surrounded\", \"editing\", \"being stood up\", \"to randomly ask\", \"getting hacked\", \"getting texts\", \"having insomnia\", \"having homework\", \"blamed\", \"showing\", \"being blamed\", \"getting bad news\", \"getting played\", \"being stood\", \"scrolling\", \"being lied too\", \"being a loner\", \"going weeks\", \"being up late\", \"having class\", \"failing\", \"being cussed\", \"listening to women\", \"when ignores\", \"cutting\", \"bring\", \"burnt\", \"getting hate\", \"coming to school\", \"sitting here\", \"waking up early\", \"being called names\", \"getting replaced\", \"having bruises\", \"closing\", \"coming back\", \"getting punched\", \"getting phone\", \"spending all day\", \"being pushed\", \"spending\", \"not being able\", \"waking\", \"working\", \"sitting\", \"walking\", \"coming home\", \"living\", \"being lied\", \"getting\", \"coming\", \"going\", \"running\", \"to sit\", \"being called\", \"to read\", \"studying\", \"paying\", \"texting\", \"hearing\", \"replying\", \"gettin better\", \"gettin better\", \"gettin\", \"eating\", \"losing\", \"listening\", \"to get up\", \"finding\", \"to clean\", \"being able\", \"seeing\", \"to run\", \"to drive\", \"to go back\", \"looking\", \"taking\", \"putting\", \"driving\", \"to start\", \"posting\", \"to pay\", \"telling me\", \"ruined\", \"being woke\", \"hitting\", \"laying\", \"cuddling\", \"reading\", \"buying\", \"cancelled\", \"sending\", \"to see pictures\", \"to find out\", \"sharing\", \"finishing\", \"sweating\", \"to miss\", \"hurting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test = pickle.load(open('march27/dataset_used-includes_train_test_split.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['NOT_SARCASM','SARCASM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def allindices(string, sub):\n",
    "    l=[]\n",
    "    i = string.find(sub)\n",
    "    while i >= 0:\n",
    "        l.append(i)\n",
    "        i = string.find(sub, i + 1)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Positive VPs</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.84      0.82      0.83      1512\n",
      "    SARCASM       0.40      0.44      0.42       412\n",
      "\n",
      "avg / total       0.75      0.74      0.74      1924\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Negative Situations</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.82      0.85      0.84      1512\n",
      "    SARCASM       0.37      0.31      0.33       412\n",
      "\n",
      "avg / total       0.72      0.74      0.73      1924\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Contrast(+VPs, –Situations), Unordered</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.81      0.94      0.87      1512\n",
      "    SARCASM       0.46      0.20      0.28       412\n",
      "\n",
      "avg / total       0.74      0.78      0.74      1924\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Contrast(+VPs, –Situations), Ordered</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.80      0.98      0.88      1512\n",
      "    SARCASM       0.60      0.12      0.21       412\n",
      "\n",
      "avg / total       0.76      0.79      0.74      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "display(HTML('<b>Positive VPs</b>'))\n",
    "for tweet in x_test:\n",
    "    predicted.append('NOT_SARCASM')\n",
    "    for posvp in orig_paper_pos_expr:\n",
    "        if posvp in tweet:\n",
    "            predicted[-1] = \"SARCASM\"\n",
    "            break\n",
    "print(metrics.classification_report(y_test,predicted,target_names=categories)) \n",
    "\n",
    "predicted = []\n",
    "display(HTML('<b>Negative Situations</b>'))\n",
    "for tweet in x_test:\n",
    "    predicted.append('NOT_SARCASM')\n",
    "    for negsit in orig_paper_neg_expr:\n",
    "        if negsit in tweet:\n",
    "            predicted[-1] = \"SARCASM\"\n",
    "            break\n",
    "print(metrics.classification_report(y_test,predicted,target_names=categories)) \n",
    "\n",
    "predicted = []\n",
    "display(HTML('<b>Contrast(+VPs, –Situations), Unordered</b>'))\n",
    "for tweet in x_test:\n",
    "    predicted.append('NOT_SARCASM')\n",
    "    for negsit in orig_paper_neg_expr:\n",
    "        break_negsit = False\n",
    "        for posvp in orig_paper_pos_expr:\n",
    "            if negsit in tweet and posvp in tweet:\n",
    "                predicted[-1] = \"SARCASM\"\n",
    "                break_negsit == True\n",
    "                break\n",
    "        if break_negsit:\n",
    "            break\n",
    "print(metrics.classification_report(y_test,predicted,target_names=categories)) \n",
    "\n",
    "predicted = []\n",
    "display(HTML('<b>Contrast(+VPs, –Situations), Ordered</b>'))\n",
    "for tweet in x_test:\n",
    "    predicted.append('NOT_SARCASM')\n",
    "    for posvp in orig_paper_pos_expr:\n",
    "        indices = allindices(tweet,posvp)\n",
    "        break_posvp = False\n",
    "        if indices:\n",
    "            for negsit in orig_paper_neg_expr:\n",
    "                for idx in indices:\n",
    "                    if negsit in tweet[idx+len(posvp):]:\n",
    "                        predicted[-1] = \"SARCASM\"\n",
    "                        break_posvp == True\n",
    "                        break\n",
    "        if break_posvp:\n",
    "            break\n",
    "print(metrics.classification_report(y_test,predicted,target_names=categories)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = pickle.load(open('results_summary.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "riloff_eval_dataset = pickle.load(open('data/riloff-emnlp/sarcasm-annos-emnlp13-tweet_objs-2124.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very low entries in this giveaway! Hop over and check it out! http://t.co/OrUSN9ne'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "riloff_eval_dataset[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "with open('data/riloff-emnlp/sarcasm-annos-emnlp13-tweets-noids.tsv') as f:\n",
    "    for line in f:\n",
    "        label,tweet = line.strip().split('\\t')\n",
    "        x.append(tweet)\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z = list(zip(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    random.shuffle(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x,y = zip(*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "c = defaultdict(int)\n",
    "for label in y:\n",
    "    c[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'NOT_SARCASM': 1666, 'SARCASM': 458})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "riloff_eval = pickle.load(open('../../riloff-tokenized-and-tagged-lowercase.pkl','rb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2124"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(riloff_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-41eab4840d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bigrams = ngrams(riloff_eval[0]['tokens'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('very', 'low'), ('low', 'entries'), ('entries', 'in'), ('in', 'this'), ('this', 'giveaway'), ('giveaway', '!'), ('!', 'hop'), ('hop', 'over'), ('over', 'and'), ('and', 'check'), ('check', 'it'), ('it', 'out'), ('out', '!'), ('!', 'http://t.co/orusn9ne')]\n"
     ]
    }
   ],
   "source": [
    "print(list(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categories = ['NOT_SARCASM','SARCASM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set_x = [tweet.lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in x[:200]]\n",
    "train_set_y = y[:200]\n",
    "test_set_x =  [tweet.lower().replace('#sarcasm','').replace('#sarcastic','') for tweet in x[200:]]\n",
    "test_set_y = y[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1087)\n",
      "(200, 1087)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_set_x)\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "\n",
    "#tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "#X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "#print(X_train_tf.shape)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_set_y)\n",
    "#To try to predict the outcome on a new document we need to extract the features using almost the same feature extracting chain as before. The difference is that we call transform instead of fit_transform on the transformers, since they have already been fit to the training set:\n",
    "#docs_new = [tweetobj['tweet'] for tweetobj in riloff_eval]\n",
    "X_new_counts = count_vect.transform(test_set_x)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "#for doc, category in zip(docs_new, predicted):\n",
    "#    print('%r => %s' % (doc, twenty_train.target_names[category]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78534303534303529"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.mean(predicted == test_set_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7718295218295218"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "np.mean(predicted == test_set_y)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    SARCASM       0.85      0.86      0.85      1511\n",
      "NOT_SARCASM       0.47      0.46      0.47       413\n",
      "\n",
      "avg / total       0.77      0.77      0.77      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766632016632\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    SARCASM       0.84      0.86      0.85      1511\n",
      "NOT_SARCASM       0.45      0.41      0.43       413\n",
      "\n",
      "avg / total       0.76      0.77      0.76      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "#print(np.mean(predicted == test_set_y))         \n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Moment of truth:\n",
    "results = pickle.load(open('results_summary.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with hinge loss\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.84      0.86      0.85      1511\n",
      "    SARCASM       0.45      0.41      0.43       413\n",
      "\n",
      "avg / total       0.76      0.77      0.76      1924\n",
      "\n",
      "B\n",
      "DatasetSarc\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1511\n",
      "    SARCASM       0.69      0.02      0.04       413\n",
      "\n",
      "avg / total       0.77      0.79      0.70      1924\n",
      "\n",
      "DatasetOther\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1511\n",
      "    SARCASM       0.50      0.01      0.01       413\n",
      "\n",
      "avg / total       0.72      0.79      0.69      1924\n",
      "\n",
      "A\n",
      "DatasetSarc\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1511\n",
      "    SARCASM       0.75      0.01      0.01       413\n",
      "\n",
      "avg / total       0.78      0.79      0.69      1924\n",
      "\n",
      "DatasetOther\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1511\n",
      "    SARCASM       1.00      0.00      0.00       413\n",
      "\n",
      "avg / total       0.83      0.79      0.69      1924\n",
      "\n",
      "C\n",
      "DatasetSarc\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1511\n",
      "    SARCASM       0.50      0.01      0.03       413\n",
      "\n",
      "avg / total       0.73      0.79      0.70      1924\n",
      "\n",
      "DatasetOther\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "NOT_SARCASM       0.79      1.00      0.88      1511\n",
      "    SARCASM       0.73      0.02      0.04       413\n",
      "\n",
      "avg / total       0.78      0.79      0.70      1924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, n_iter=5, random_state=42)),\n",
    "])\n",
    "_ = text_clf.fit(train_set_x, train_set_y)\n",
    "predicted = text_clf.predict(test_set_x)\n",
    "#print(np.mean(predicted == test_set_y)) \n",
    "print(\"SVM with hinge loss\")\n",
    "print(metrics.classification_report(test_set_y, predicted,\n",
    "    target_names=categories))\n",
    "\n",
    "for _id,resultset in results.items():\n",
    "    print(_id)\n",
    "    for dataset,wordsets in resultset.items():\n",
    "        predicted = []\n",
    "        if dataset == 'shereen': \n",
    "            print('DatasetSarc')\n",
    "        else: \n",
    "            print('DatasetOther')\n",
    "        #print(dataset)\n",
    "        for tweet in test_set_x:\n",
    "            predicted.append('NOT_SARCASM')\n",
    "            for posphrase in wordsets['pos']:\n",
    "                if posphrase in tweet:\n",
    "                    for negphrase in wordsets['neg']:\n",
    "                        if negphrase in tweet:\n",
    "                            predicted[-1] = \"SARCASM\"\n",
    "        print(metrics.classification_report(test_set_y,predicted,target_names=categories))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c = defaultdict(int)\n",
    "for label in test_set_y:\n",
    "    c[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'NOT_SARCASM': 1511, 'SARCASM': 413})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27332892124420916"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "413/1511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ashish/Desktop/245/Project/code'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
